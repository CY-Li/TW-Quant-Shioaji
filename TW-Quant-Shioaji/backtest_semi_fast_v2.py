import pandas as pd
import numpy as np
import json
import os
import sys
from datetime import datetime, timedelta
import multiprocessing
from functools import partial

# å°‡å°ˆæ¡ˆè·¯å¾‘åŠ å…¥ä»¥å¼•ç”¨æ¨¡çµ„
sys.path.append(os.getcwd())
sys.path.append(os.path.join(os.getcwd(), "TW-Quant-Shioaji"))

from core.integrated_stock_analyzer import IntegratedStockAnalyzer
sys.path.append(os.path.join(os.getcwd(), "BullPS-v3"))
from backend.portfolio_manager import evaluate_smart_sar_exit, evaluate_exit_confidence

# é…ç½®
DATA_DIR = "TW-Quant-Shioaji/data/batch_semi"
INDEX_FILE = f"{DATA_DIR}/twii.csv"
SEMI_LIST_FILE = "TW-Quant-Shioaji/semi_10.json"
REPORT_FILE = "TW-Quant-Shioaji/semi_backtest_optimized_report.json"

ENTRY_THRESHOLD_BASE = 65
CAPITAL = 1000000
MAX_POSITIONS = 5 # æ—¢ç„¶åªæœ‰10æ”¯ï¼ŒåŒæ™‚æŒæœ‰5æ”¯ç®—å¤šäº†
POS_SIZE_PCT = 0.2
COST = 0.005

def process_stock_data(sym, data_dir):
    try:
        print(f"  ğŸ§µ æ­£åœ¨è™•ç† {sym}...")
        p = f"{data_dir}/{sym}.csv"
        if os.path.exists(p):
            df = pd.read_csv(p)
            df['Date'] = pd.to_datetime(df['Date'])
            df.set_index('Date', inplace=True)
            
            # ä½¿ç”¨ Analyzer è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            analyzer = IntegratedStockAnalyzer() 
            df = analyzer.calculate_technical_indicators(df)
            print(f"  âœ… {sym} æŒ‡æ¨™è¨ˆç®—å®Œæˆ")
            return sym, df
    except Exception as e:
        print(f"Error processing {sym}: {e}")
    return sym, None

def run_backtest():
    with open(SEMI_LIST_FILE, "r") as f:
        symbols = json.load(f)
    
    # 1. é åŠ è¼‰å¤§ç›¤æ•¸æ“š
    mdf = pd.read_csv(INDEX_FILE)
    mdf['Date'] = pd.to_datetime(mdf['Date'])
    mdf.set_index('Date', inplace=True)
    mdf['MA5'] = mdf['Close'].rolling(5).mean()

    # 2. é åŠ è¼‰å€‹è‚¡æ•¸æ“š (å¤šé€²ç¨‹)
    all_data = {}
    all_dates = set()
    print(f"ğŸ”„ æ­£åœ¨è¨ˆç®—æŒ‡æ¨™ (ä½¿ç”¨ {multiprocessing.cpu_count()} æ ¸å¿ƒ)...")
    
    with multiprocessing.Pool() as pool:
        worker = partial(process_stock_data, data_dir=DATA_DIR)
        results = pool.map(worker, symbols)
        
    for sym, df in results:
        if df is not None:
            all_data[sym] = df
            all_dates.update(df.index.tolist())

    sorted_dates = sorted(list(all_dates))
    # åªçœ‹æœ€è¿‘å…©å¹´
    bt_start_date = datetime.now() - timedelta(days=2*365)
    sorted_dates = [d for d in sorted_dates if d >= bt_start_date]

    print(f"ğŸš€ å•Ÿå‹•åŠå°é«”å›æ¸¬ï¼Œç¸½äº¤æ˜“å¤©æ•¸: {len(sorted_dates)}")
    if len(sorted_dates) == 0:
        print("âŒ éŒ¯èª¤: æ²’æœ‰å¯ç”¨çš„å›æ¸¬æ—¥æœŸã€‚è«‹æª¢æŸ¥æ•¸æ“šç¯„åœã€‚")
        return None
    
    capital = CAPITAL
    active_positions = []
    trade_log = []
    analyzer = IntegratedStockAnalyzer()
    # é è¨­ä¸­æ€§æƒ…ç·’ä»¥åŠ é€Ÿå›æ¸¬ï¼Œé¿å…é‡è¤‡ä¸‹è¼‰å¤§ç›¤æ•¸æ“š
    analyzer.market_sentiment = {'sentiment': 'neutral', 'score': 50, 'factors': ['Backtest Neutral']}
    # ç¦ç”¨ MTF åˆ†æä»¥åŠ é€Ÿå›æ¸¬ï¼Œé˜²æ­¢å›åœˆå…§å¤§é‡ä¸‹è¼‰æ•¸æ“š
    analyzer.mtf_analyzer.calculate_multi_timeframe_score = lambda sym: {
        'final_score': 50, 
        'trend_consistency': 0.5, 
        'recommendation': ['MTF Disabled for Speed']
    }

    total_days = len(sorted_dates)
    for idx, date in enumerate(sorted_dates):
        # é¡¯ç¤ºæ¯æ—¥é€²åº¦
        print(f"  ğŸ“… è™•ç†æ—¥æœŸ: {date.date()} ({idx+1}/{total_days})", flush=True)
        
        # --- A. å‡ºå ´æª¢æŸ¥ ---
        for pos in active_positions[:]:
            df = all_data[pos['symbol']]
            if date in df.index:
                loc = df.index.get_loc(date)
                # æº–å‚™åˆ†æå¿«ç…§
                current_analysis = {
                    'symbol': pos['symbol'],
                    'current_price': df.loc[date, 'Close'],
                    'sar': df.loc[date, 'SAR'],
                    'rsi': df.loc[date, 'RSI'],
                    'macd': df.loc[date, 'MACD'],
                    'macd_histogram': df.loc[date, 'MACD_Histogram'],
                    'volume_ratio': df.loc[date, 'Volume_Ratio'],
                    'ma20': df.loc[date, 'MA20'],
                    'ma5': df.loc[date, 'MA5'],
                    'confidence_factors': [] # ç‚ºäº†é€Ÿåº¦
                }
                
                # åŸ·è¡Œæ™ºèƒ½å‡ºå ´
                sar_res = evaluate_smart_sar_exit(pos, current_analysis, current_dt=date)
                conf_res = evaluate_exit_confidence(pos, current_analysis)
                
                if sar_res['should_exit'] or conf_res['exit_confidence'] >= 0.8:
                    exit_p = df.loc[date, 'Close']
                    pnl = (exit_p - pos['entry_price']) / pos['entry_price'] - COST
                    capital += (pos['entry_price'] * pos['shares']) * (1 + pnl)
                    trade_log.append({
                        'symbol': pos['symbol'], 
                        'entry_date': str(pos['entry_date'].date()),
                        'exit_date': str(date.date()),
                        'pnl': round(pnl * 100, 2)
                    })
                    active_positions.remove(pos)

        # --- B. é€²å ´æƒæ ---
        if len(active_positions) < MAX_POSITIONS:
            # å¤§ç›¤æº«åº¦è¨ˆ
            if date in mdf.index:
                m_close = mdf.loc[date, 'Close']
                m_ma5 = mdf.loc[date, 'MA5']
                threshold = ENTRY_THRESHOLD_BASE * (1.15 if m_close <= m_ma5 else 1.0)
            else:
                threshold = ENTRY_THRESHOLD_BASE

            candidates = []
            for sym, df in all_data.items():
                if any(p['symbol'] == sym for p in active_positions): continue
                if date in df.index:
                    loc = df.index.get_loc(date)
                    if loc < 60: continue
                    
                    try:
                        # æ¨¡æ“¬ Analyzer è©•ä¼°
                        _, score, _, factors = analyzer.assess_entry_opportunity(df.iloc[:loc+1])
                        if score >= threshold:
                            candidates.append({
                                'symbol': sym, 
                                'score': score, 
                                'price': df.loc[date, 'Close'], 
                                'factors': factors
                            })
                    except:
                        pass
            
            candidates = sorted(candidates, key=lambda x: x['score'], reverse=True)
            while len(active_positions) < MAX_POSITIONS and candidates:
                c = candidates.pop(0)
                invest = capital * POS_SIZE_PCT
                shares = invest / c['price']
                active_positions.append({
                    'symbol': c['symbol'],
                    'entry_price': c['price'],
                    'entry_date': date,
                    'shares': shares,
                    'initial_analysis_snapshot': {'confidence_factors': c['factors']}
                })
                capital -= invest

    final_val = capital + sum([all_data[p['symbol']].loc[sorted_dates[-1], 'Close'] * p['shares'] for p in active_positions if sorted_dates[-1] in all_data[p['symbol']].index])
    wr = len([t for t in trade_log if t['pnl'] > 0]) / len(trade_log) if trade_log else 0
    
    report = {
        "strategy": "BullPS-TW-Optimized-v1",
        "period": "2y (Semiconductor Focus)",
        "initial_capital": CAPITAL,
        "final_equity": round(final_val, 2),
        "total_return": f"{round((final_val - CAPITAL)/CAPITAL * 100, 2)}%",
        "win_rate": f"{round(wr * 100, 2)}%",
        "total_trades": len(trade_log),
        "trades": trade_log
    }
    
    with open(REPORT_FILE, "w", encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    return report

if __name__ == "__main__":
    res = run_backtest()
    print(f"\nğŸ“Š å›æ¸¬å ±å‘Šæ‘˜è¦ï¼š")
    print(f"ç¸½æŠ•å ±ç‡: {res['total_return']}")
    print(f"å‹ç‡: {res['win_rate']}")
    print(f"äº¤æ˜“æ¬¡æ•¸: {res['total_trades']}")
    print(f"æœ€çµ‚è³‡ç”¢: {res['final_equity']}")
